{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №3 \n",
    "## Обучение моделей глубокого обучения на PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.3-cp37-cp37m-win_amd64.whl (8.5 MB)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in c:\\users\\sasha\\pymol\\lib\\site-packages (from matplotlib) (7.1.2)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-win_amd64.whl (51 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\users\\sasha\\pymol\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15 in c:\\users\\sasha\\pymol\\lib\\site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\sasha\\pymol\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.3 pyparsing-2.4.7\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, List, Type, Dict, Any\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача на этой неделе - повторить модель трёхслойного перцептрона из прошолго задания на **PyTorch**, разобрать лучшие практики обучения моделей глубокого обучения и провести серию экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы эксперимент можно было повторить, хорошей практикой будет зафиксировать генератор случайных чисел. Также, рекоммендуется зафиксировать RNG в numpy и, если в качестве бэкенда используется cudnn - включить детерминированный режим.\n",
    "\n",
    "Подробнее: https://pytorch.org/docs/stable/notes/randomness.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель\n",
    "\n",
    "Основным способом организации кода на **Pytorch** является модуль. Простые модели могут быть реализованны из готовых модулей ( к примеру, `torch.nn.Sequential`, `torch.nn.Linear` и т.д. ), для более сложных архитектур часто приходтся реализовывать собственные блоки. Это достаточно легко сделать - достаточно написать класс, наследуемый от `torch.nn.Module` и реализующий метод `.forward`, который принимает и возвращает тензоры ( `torch.Tensor` )\n",
    "\n",
    "Пример реализации кастомного модуля из официальной документации: https://pytorch.org/tutorials/beginner/pytorch_with_examples.html3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "\n",
    "Повторите реализацию трёхслойного перцептрона из предыдущего задания на **Pytorch**. Желательно также, чтобы реализация модели имела параметризуемую глубину ( количество слоёв ), количество параметров на каждом слое и функцию активации. Отсутствие такой возможности не снижает балл, но сильно поможет в освоении принципов построения нейросетей с применением библиотеки pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_resolution: Tuple[int, int] = (28, 28),\n",
    "                 input_channels: int = 1, \n",
    "                 hidden_layer_features: List[int] = [256, 256],\n",
    "                 activation: Type[torch.nn.Module] = torch.nn.ReLU,\n",
    "                 num_classes: int = 10):\n",
    "\n",
    "        super( ).__init__()\n",
    "        \n",
    "\n",
    "        self.input_layer = nn.Linear(input_resolution[0]*input_resolution[1], 256)\n",
    "        self.hidden_layers  = nn.ModuleList()\n",
    "        self.drop_layer = nn.Dropout(p=0.2)\n",
    "        \n",
    "        for i in range(len(hidden_layer_features)-1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_layer_features[i], hidden_layer_features[i+1]))\n",
    "        \n",
    "        self.output_layer = nn.Linear(256, num_classes)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        input_image = x.view(x.size(0), -1)\n",
    "        \n",
    "        output = self.input_layer(input_image)\n",
    "        output = F.relu(output)\n",
    "        output = self.drop_layer(output)\n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            output = layer(output)\n",
    "            output = F.relu(output)\n",
    "            output = self.drop_layer(output)\n",
    "        \n",
    "        # Get predictions\n",
    "        output = self.output_layer(output)\n",
    "        return output\n",
    "    \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий код позволяет посмотреть архитектуру получившейся модели и общее количество обучаемых параметров. Мы хотим, чтобы количество параметров в модели было порядка сотен тысяч. Если у вас получается больше или меньше, попробуйте изменить архитектуру модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(\n",
      "  (input_layer): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (drop_layer): Dropout(p=0.2, inplace=False)\n",
      "  (output_layer): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Total number of trainable parameters 269322\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron()\n",
    "print(model)\n",
    "print('Total number of trainable parameters', \n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающая выборка\n",
    "\n",
    "На практике, наиболее важным для успеха обучения любой модели машинного обучения является этап подготовки данных. Модели глубокого обучения не являются исключением. Большая, чистая, репрезентативная и релевантная поставленной задаче обучающая выборка часто важнее, чем архитектура самой модели. В предлагаемой задаче используется качественный и проверенный временем MNIST. Однако в практических задачах часто будет получаться так, что лучшим способом добиться улучшения качества модели будет сбор дополнительных данных и очистка исходных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных\n",
    "\n",
    "Для улучшения сходимости алгоритма обучения и качества полученной модели данные могут быть предварительно обработаны:\n",
    "\n",
    "1. Среднее каждой входной переменной близко к нулю\n",
    "2. Переменные отмасштабированы таким образом, что их дисперсии примерно одинаковы ( из соображений вычислительной устойчивости, мы хотим, чтобы все величины по порядку величины были близки к еденице )\n",
    "3. По возможности, входные переменные не должны быть скоррелированны. Важнось этого пункта в последние годы ставится под сомнение, но всё-же в некоторых случаях это может влиять на результат\n",
    "\n",
    "Подробнее можно почитать здесь: http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментация (искусственное дополнение) обучающей выборки\n",
    "\n",
    "В зависимости от задачи можно применять к признаковому описанию объектов обучающей выборки различные преобразования, которые позволят увеличить эффективный размер выборки без дополнительной разметки. К примеру, для задачи классификации кошек и собак можно зеркально отразить изображение вокруг вертикальной оси - при этом класс изображения не изменится, а само изображение останется по прежнему будет принадлежать исходному распределению. Есть много разных техник аугментации, и их применимость и эффективность сильно зависит от данных и задачи.\n",
    "\n",
    "Подробнее можно почитать здесь: https://link.springer.com/content/pdf/10.1186/s40537-019-0197-0.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Обоснуйте, почему аугментация обучающей выборки позволяет добиться прироста качества модели, несмотря на то, что она не добавляет в неё дополнительную информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Потому что таким образом, мы пытаемся снизить переобученность так как наша нейронная модель будет \"пытаться\" обобщить свои выводы и \"стараться\" снизить влияние искажающих или ненужных факторов.  Например: может перестают обращать внимание на поворот картинки, фон, цвет и прочее.  Или в другой формулировке - мы не дает новой информации, но говорим, на что в этом случаее надо обращать внимание.\n",
    "\n",
    "\n",
    "#### Так же, аугментация может использоваться для акцента на тех количественно небольших случаев, с которыми модель плохо справилась, чтобы \"доучиться\". То есть мы \"раздуваем\" количество сложных/редких случаев. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "\n",
    "Какие осмысленные аугментации вы можете придумать для следующих наборов данных:\n",
    "\n",
    "1. Набор изображений животных, размеченый на виды животных\n",
    "2. Набор аудиозаписей голоса, размечеными на языки говорящего\n",
    "3. Набор cо показаниями датчиков температуры, влажности и давления с одной из метеостанций, размеченый на признак наличия осадков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Your text here\n",
    "1. Отражение, вращение, кручение, сдвиг - Принцип такой: зебра, смотрящая налево, остается зеброй, если её отразить по вертикали.\n",
    "2. Добавление фонового звука. \n",
    "3. Добавить шум. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "\n",
    "Напишите пайплайн для предобработки и аугументации данных. В `torchvision.transforms` есть готовые реализации большинства распространённых техник. Если вы хотите добавить что-то своё, вы можете воспользоваться `torchvision.transforms.Lambda`. При этом следует понимать, что если нужно оценить качество модели на оригинальных данных, пайплайн предварительной обработки данных валидационной выборки не должен включать аугментаций. Следует помнить, однако, что существует подход аугментации данных в момент применения модели (test-time augmentation), который позволяет повысить качество модели в режиме исполнения.\n",
    "\n",
    "Одним из обязательных шагов в вашем пайплайне должна быть конвертация данных в тензоры Pytorch (`torch.Tensor`): `torchvision.transforms.ToTensor()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([  # your core here\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e8c0fc64e340ffacc36a5910e84819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cf5cadb9544fd490a8986994d97dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa182567c3c497aaded03c2bcd503aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3343e5ed0c88425a8300e788436e04e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasha\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:457: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./mnist', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=train_transforms)\n",
    "\n",
    "val_dataset = torchvision.datasets.MNIST(root='./mnist', \n",
    "                                         train=False, \n",
    "                                         download=True, \n",
    "                                         transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./mnist\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как запускать обучение всегда стоит посмотреть на данные после предобработки, и удостовериться, что они соответствуют ожидаемым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, len(train_dataset), size=256)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=16, ncols=16, figsize=(32, 32))\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        sample_index = indices[i*16+j]\n",
    "        sample, label = train_dataset[sample_index]\n",
    "        ax.imshow(sample.cpu().numpy().transpose(1, 2, 0))\n",
    "        ax.set_title(label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "\n",
    "Теперь, когда мы реализовали модель и подготовили данные мы можем приступить к непосредственному обучению модели. Костяк функции обучения написан ниже, далее вы должны будете реализовать ключевые части этого алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "def train_model(model: torch.nn.Module, \n",
    "                train_dataset: torch.utils.data.Dataset,\n",
    "                val_dataset: torch.utils.data.Dataset,\n",
    "                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n",
    "                optimizer_params: Dict = {},\n",
    "                initial_lr = 0.01,\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                batch_size = 64,\n",
    "                max_epochs = 50,\n",
    "                early_stopping_patience = 20):\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, **optimizer_params)\n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_epoch = None\n",
    "    epoch_train_losses = []\n",
    "    \n",
    "    #pbar = tqdm(total=max_epochs)\n",
    "    for epoch in range(max_epochs) :\n",
    "        \n",
    "        print(f'Epoch {epoch}')\n",
    "        loss_train = train_single_epoch(model, optimizer, loss_function, train_loader)\n",
    "        val_metrics = validate_single_epoch(model, loss_function, val_loader)\n",
    "        print(f'Validation metrics: \\n{val_metrics}')\n",
    "\n",
    "        lr_scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        if best_val_loss is None or best_val_loss > val_metrics['loss']:\n",
    "            print(f'Best model yet, saving')\n",
    "            best_val_loss = val_metrics['loss']\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, './best_model.pth')\n",
    "            \n",
    "        if epoch - best_epoch > early_stopping_patience:\n",
    "            print('Early stopping triggered')\n",
    "            return\n",
    "        \n",
    "        #pbar.update(1)\n",
    "        #pbar.set_postfix({'loss': val_metrics})\n",
    "    \n",
    "    #tqdm.close()\n",
    "        #epoch_train_losses.append(loss_train)\n",
    "        #epoch_train_losses.append(val_metrics['loss'])\n",
    "        #plt.plot(epoch_train_losses)\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5\n",
    "\n",
    "Реализуйте функцию, производящую обучение сети на протяжении одной эпохи ( полного прохода по всей обучающей выборке ). На вход будет приходить модель, оптимизатор, функция потерь и объект типа `DataLoader`. При итерировании по `data_loader` вы будете получать пары вида ( данные, целевая_переменная )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                       optimizer: torch.optim.Optimizer, \n",
    "                       loss_function: torch.nn.Module, \n",
    "                       data_loader: torch.utils.data.DataLoader,\n",
    "                       max_epochs = 1):\n",
    "    \n",
    "    epoch_train_losses = []\n",
    "    #print(len(data_loader))\n",
    "    for X_batch, y_batch in data_loader:\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_function(y_pred, y_batch)\n",
    "\n",
    "        # зануляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # ОБНОВЛЯЕМ веса\n",
    "        optimizer.step()\n",
    "        epoch_train_losses.append(loss.item())    \n",
    "        # Запишем число (не тензор) в наши батчевые лоссы\n",
    "    return np.mean(epoch_train_losses)\n",
    " \n",
    "#     plt.plot(epoch_train_losses)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6\n",
    "\n",
    "Реализуйте функцию производящую вычисление функции потерь на валидационной выборке.  На вход будет приходить модель, функция потерь и `DataLoader`. На выходе ожидается словарь с вида:\n",
    "```\n",
    "{\n",
    "    'loss': <среднее значение функции потерь>,\n",
    "    'accuracy': <среднее значение точности модели>\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                          loss_function: torch.nn.Module, \n",
    "                          data_loader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    D = {}\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        inputs, labels = data\n",
    "        #print(inputs.shape, labels.shape)\n",
    "        #inputs, labels = data[0].to(device), data[1].to(device)  \n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        losses.append(loss.item()) #loss_function(x,y)\n",
    "        \n",
    "        labels_pred = np.argmax(outputs.detach().numpy(), axis=1)\n",
    "        \n",
    "        accuracy = accuracy_score(labels_pred, labels)\n",
    "        accuracies.append(accuracy)\n",
    "    #print(np.mean(losses))\n",
    "    \n",
    "    D['loss'] = np.mean(losses)\n",
    "    D['accuracy'] = np.mean(accuracies)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы корректно реализовали все предыдущие шаги и ваша модель имеет достаточное количество обучаемых параметров, то в следующей ячейке должен пойти процесс обучения, и мы должны достичь итоговой точности (в смысле меры accuracy, доли верных ответов) выше 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Validation metrics: \n",
      "{'loss': 0.5523548189811646, 'accuracy': 0.8190684713375797}\n",
      "Best model yet, saving\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\sasha\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Perceptron. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: \n",
      "{'loss': 0.4103707963968538, 'accuracy': 0.8683320063694268}\n",
      "Best model yet, saving\n",
      "Epoch 2\n",
      "Validation metrics: \n",
      "{'loss': 0.39059766246729594, 'accuracy': 0.8729100318471338}\n",
      "Best model yet, saving\n",
      "Epoch 3\n",
      "Validation metrics: \n",
      "{'loss': 0.34966683577580054, 'accuracy': 0.8912221337579618}\n",
      "Best model yet, saving\n",
      "Epoch 4\n",
      "Validation metrics: \n",
      "{'loss': 0.3430380040103463, 'accuracy': 0.88953025477707}\n",
      "Best model yet, saving\n",
      "Epoch 5\n",
      "Validation metrics: \n",
      "{'loss': 0.2928224984959812, 'accuracy': 0.9075437898089171}\n",
      "Best model yet, saving\n",
      "Epoch 6\n",
      "Validation metrics: \n",
      "{'loss': 0.2874333345016856, 'accuracy': 0.9077428343949044}\n",
      "Best model yet, saving\n",
      "Epoch 7\n",
      "Validation metrics: \n",
      "{'loss': 0.2580317619262607, 'accuracy': 0.918093152866242}\n",
      "Best model yet, saving\n",
      "Epoch 8\n",
      "Validation metrics: \n",
      "{'loss': 0.28414101153612137, 'accuracy': 0.9093351910828026}\n",
      "Epoch 9\n",
      "Validation metrics: \n",
      "{'loss': 0.24769758668010403, 'accuracy': 0.9214769108280255}\n",
      "Best model yet, saving\n",
      "Epoch 10\n",
      "Validation metrics: \n",
      "{'loss': 0.26281507182747693, 'accuracy': 0.918093152866242}\n",
      "Epoch 11\n",
      "Validation metrics: \n",
      "{'loss': 0.241265165696668, 'accuracy': 0.9231687898089171}\n",
      "Best model yet, saving\n",
      "Epoch 12\n",
      "Validation metrics: \n",
      "{'loss': 0.22690219161616768, 'accuracy': 0.9276472929936306}\n",
      "Best model yet, saving\n",
      "Epoch 13\n",
      "Validation metrics: \n",
      "{'loss': 0.2504604069195735, 'accuracy': 0.9223726114649682}\n",
      "Epoch 14\n",
      "Validation metrics: \n",
      "{'loss': 0.23285893901328372, 'accuracy': 0.925656847133758}\n",
      "Epoch 15\n",
      "Validation metrics: \n",
      "{'loss': 0.21848072068896263, 'accuracy': 0.931031050955414}\n",
      "Best model yet, saving\n",
      "Epoch 16\n",
      "Validation metrics: \n",
      "{'loss': 0.20700789783980436, 'accuracy': 0.93640525477707}\n",
      "Best model yet, saving\n",
      "Epoch 17\n",
      "Validation metrics: \n",
      "{'loss': 0.2401216325771277, 'accuracy': 0.9225716560509554}\n",
      "Epoch 18\n",
      "Validation metrics: \n",
      "{'loss': 0.20850709766434256, 'accuracy': 0.9339171974522293}\n",
      "Epoch 19\n",
      "Validation metrics: \n",
      "{'loss': 0.21162306824639723, 'accuracy': 0.9334195859872612}\n",
      "Epoch 20\n",
      "Validation metrics: \n",
      "{'loss': 0.19888165270446972, 'accuracy': 0.9386942675159236}\n",
      "Best model yet, saving\n",
      "Epoch 21\n",
      "Validation metrics: \n",
      "{'loss': 0.2261979648499352, 'accuracy': 0.9295382165605095}\n",
      "Epoch 22\n",
      "Validation metrics: \n",
      "{'loss': 0.18985630117451688, 'accuracy': 0.9403861464968153}\n",
      "Best model yet, saving\n",
      "Epoch 23\n",
      "Validation metrics: \n",
      "{'loss': 0.20580605220547907, 'accuracy': 0.9343152866242038}\n",
      "Epoch 24\n",
      "Validation metrics: \n",
      "{'loss': 0.1980414971424516, 'accuracy': 0.9390923566878981}\n",
      "Epoch 25\n",
      "Validation metrics: \n",
      "{'loss': 0.19616139924545198, 'accuracy': 0.9417794585987261}\n",
      "Epoch 26\n",
      "Validation metrics: \n",
      "{'loss': 0.2003622186981189, 'accuracy': 0.9372014331210191}\n",
      "Epoch 27\n",
      "Validation metrics: \n",
      "{'loss': 0.19024697954582562, 'accuracy': 0.941281847133758}\n",
      "Epoch 28\n",
      "Validation metrics: \n",
      "{'loss': 0.1856522403752348, 'accuracy': 0.9398885350318471}\n",
      "Best model yet, saving\n",
      "Epoch 29\n",
      "Validation metrics: \n",
      "{'loss': 0.1943050382101232, 'accuracy': 0.9409832802547771}\n",
      "Epoch 30\n",
      "Validation metrics: \n",
      "{'loss': 0.18577255569635684, 'accuracy': 0.9424761146496815}\n",
      "Epoch 31\n",
      "Validation metrics: \n",
      "{'loss': 0.20156590494617915, 'accuracy': 0.9373009554140127}\n",
      "Epoch 32\n",
      "Validation metrics: \n",
      "{'loss': 0.2051528745396122, 'accuracy': 0.9398885350318471}\n",
      "Epoch 33\n",
      "Validation metrics: \n",
      "{'loss': 0.19506327510117347, 'accuracy': 0.9400875796178344}\n",
      "Epoch 34\n",
      "Validation metrics: \n",
      "{'loss': 0.19998988214951413, 'accuracy': 0.93859474522293}\n",
      "Epoch 35\n",
      "Validation metrics: \n",
      "{'loss': 0.1997944479392972, 'accuracy': 0.9371019108280255}\n",
      "Epoch 36\n",
      "Validation metrics: \n",
      "{'loss': 0.20361393878746564, 'accuracy': 0.9355095541401274}\n",
      "Epoch 37\n",
      "Validation metrics: \n",
      "{'loss': 0.19955319554135678, 'accuracy': 0.9368033439490446}\n",
      "Epoch 38\n",
      "Validation metrics: \n",
      "{'loss': 0.20192224454063518, 'accuracy': 0.9373009554140127}\n",
      "Epoch 39\n",
      "Validation metrics: \n",
      "{'loss': 0.20597624577059867, 'accuracy': 0.9368033439490446}\n",
      "Epoch 40\n",
      "Validation metrics: \n",
      "{'loss': 0.16252179522138493, 'accuracy': 0.9505374203821656}\n",
      "Best model yet, saving\n",
      "Epoch 41\n",
      "Validation metrics: \n",
      "{'loss': 0.16306594096029262, 'accuracy': 0.9516321656050956}\n",
      "Epoch 42\n",
      "Validation metrics: \n",
      "{'loss': 0.16017716665081916, 'accuracy': 0.9509355095541401}\n",
      "Best model yet, saving\n",
      "Epoch 43\n",
      "Validation metrics: \n",
      "{'loss': 0.16193491890789216, 'accuracy': 0.95203025477707}\n",
      "Epoch 44\n",
      "Validation metrics: \n",
      "{'loss': 0.159979571855277, 'accuracy': 0.9503383757961783}\n",
      "Best model yet, saving\n",
      "Epoch 45\n",
      "Validation metrics: \n",
      "{'loss': 0.16140965044878092, 'accuracy': 0.9511345541401274}\n",
      "Epoch 46\n",
      "Validation metrics: \n",
      "{'loss': 0.16036935671452124, 'accuracy': 0.9515326433121019}\n",
      "Epoch 47\n",
      "Validation metrics: \n",
      "{'loss': 0.15873751835600966, 'accuracy': 0.9522292993630573}\n",
      "Best model yet, saving\n",
      "Epoch 48\n",
      "Validation metrics: \n",
      "{'loss': 0.15848068957021283, 'accuracy': 0.9541202229299363}\n",
      "Best model yet, saving\n",
      "Epoch 49\n",
      "Validation metrics: \n",
      "{'loss': 0.15672045736128737, 'accuracy': 0.9524283439490446}\n",
      "Best model yet, saving\n"
     ]
    }
   ],
   "source": [
    "#model.to(device)\n",
    "train_model(model, \n",
    "            train_dataset=train_dataset, \n",
    "            val_dataset=val_dataset, \n",
    "            loss_function=torch.nn.CrossEntropyLoss(), \n",
    "            initial_lr=0.0004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7\n",
    "\n",
    "Модифицируйте процесс обучения таким образом, чтобы достигнуть наилучшего качества на валидационной выборке. Модель должна оставаться N-слойным перцептроном с количеством обучаемых параметров <= 500000. Для обучения разрешается использовать только набор данных MNIST. Процесс обучения вы можете изменять по собственному усмотрению. К примеру, вы можете менять:\n",
    "\n",
    "* Архитектуру модели в рамках наложенных ограничений на количество параметров и вид архитектуры (многослойный перцептрон)\n",
    "* Функции активации в модели\n",
    "* Используемый оптимизатор\n",
    "* Расписание шага оптимизации\n",
    "* Сэмплинг данных при обучении ( e.g. hard negative mining)\n",
    "\n",
    "В результате мы ожидаем увидеть код экспериментов и любые инсайты, которые вы сможете получить в процессе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучил улучшенную модель до 90% и выше\n",
    "\n",
    "(Последняя эпоха дала 95.2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметил, что классы 6 и 9 можно отражать по вертикале, чтобы сгенерить дополнительные новые данные для этих классов, а класс 8 можно отражать по вертикали и горизонтале при аугументации "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
